{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca7a284-e03a-40fe-889a-f8880766c266",
   "metadata": {},
   "source": [
    "# RL for fAIr Demo\n",
    "(see description for custom environment help is needed and ANYONE can help) \n",
    "## What is RL?\n",
    "Reinforcement Learning is when an agent learns how to do something by recieving good/bad feedback. In our case, an agent would learn how to optimize fertilization on different farms. \n",
    "\n",
    "#### Reasons why RL might be a good idea: \n",
    "- High Adaptabilility to Different Environments:  RL is very dynamic and can model complex situations. For example, temperature, soil moisture levels, etc... are all dynamic variables and make fertilization different each time. RL is great for accounting for any situation. \n",
    "  \n",
    "- Optimization: The agent can 'simulate' optimal fertilization beforehand. For example, a farmer will know beforehand how much fertilizer is needed, where to apply the most fertilizer, etc...\n",
    "\n",
    "- Very awesome\n",
    "\n",
    "#### Reasons why we might choose a different software\n",
    "\n",
    "- Complexity: Creating a environment detailed enough will be a big challenge -- it will take a very very deep understanding of the problem. Thankfully, however, **anyone can help make the environment better by just expanding our knowledge of the problem** (I will elaborate on this below).\n",
    "\n",
    "- Simulation Gap: As an add on to the problem above, if we don't model the farm very well, it can lead to it not being so effective on the field\n",
    "  \n",
    "\n",
    "### Resources\n",
    "\n",
    "[Nicholas Renotte Series](https://www.youtube.com/playlist?list=PLgNJO2hghbmjlE6cuKMws2ejC54BTAaWV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca3216-ccf3-4d07-86a6-26ae893716a1",
   "metadata": {},
   "source": [
    "# Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b1293a9-bbe3-4c15-bee9-0f976a2194b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from gym) (1.26.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from gym) (3.1.1)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (2.2.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (1.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (4.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: keras-rl2 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from keras-rl2) (2.10.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (2.2.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (3.13.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (1.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (24.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (4.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (1.17.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorflow->keras-rl2) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.45.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (1.26.0)\n",
      "Requirement already satisfied: pygame in c:\\users\\sotiv\\anaconda3\\envs\\tf_env\\lib\\site-packages (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym\n",
    "!pip install tensorflow\n",
    "!pip install keras-rl2 \n",
    "!pip install numpy\n",
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902f4ec4-e23a-4a34-9e5b-54c0ba3a029b",
   "metadata": {},
   "source": [
    "# Creating Environment / Custom Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398f5400-11f1-4e6d-8e62-e972703d0b31",
   "metadata": {},
   "source": [
    "### How Everyone Can Help\n",
    "\n",
    "To teach the agent how to fertilize, we have to design an environment and how it can interact with it. In this case, we have to design a farm and how the agent can engage with it. \n",
    "\n",
    "To help,  research:\n",
    "- **what defines the condition of the farm**. For example, soil moisture, temperature, nitrogen levels, and nutrient levels all define the condition of the farm.\n",
    "- **what actions can the agent take**:  For example, the agent could add more fertilizer, it could wait a day, it could stop fertilizing, etc...\n",
    "\n",
    "Obviously you'll notice that we have a very surface level understanding of how to describe the farm and how to interact with the farm. General research into this helps design it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "121cc8be-e759-428a-9dc4-ef455660b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df23fd86-0a4d-4ae4-acf0-32da07dae9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEnv(Env):\n",
    "    def __init__(self): #actions, observation space, space, shower length \n",
    "        \n",
    "        self.action_space = Discrete(3) #this will refer to the actions the agent can take\n",
    "        self.observation_space = Box(low=np.array([0]), high=np.array([100]), dtype=np.float32) #display current state, but could be used to hold n-dimensional factors\n",
    "        self.state = 38 + random.randint(-3,3) #starting state\n",
    "        self.length = 60 # how many episodes\n",
    "        \n",
    "    def step(self, action): #what we do when we take a step, how we treat actions\n",
    "\n",
    "        self.state += action -1 \n",
    "        self.length -= 1 #each episode decrease episode\n",
    "        \n",
    "        if self.state >=37 and self.state <=39: # set optimal, and reward. also could be extended to n factors.\n",
    "            reward =1 \n",
    "        else: \n",
    "            reward = -1 #discourage other stuff\n",
    "        \n",
    "        # Check if shower is done\n",
    "        if self.shower_length <= 0: \n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "            \n",
    "        self.state += random.randint(-1,1)\n",
    "\n",
    "        info = {}\n",
    "        \n",
    "        return self.state, reward, done, info\n",
    "        \n",
    "    def render(self): #visualizations\n",
    "        pass\n",
    "    def reset(self): #reset environment after each episode\n",
    "        self.state = 38 + random.randint(-3,3)\n",
    "        self.shower_length = 60 \n",
    "        return np.array([self.state], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61ac50a7-fcd8-4845-98f9-91d4bfc4fb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sotiv\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\gym\\spaces\\box.py:128: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([88.90683], dtype=float32), 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = CustomEnv()\n",
    "env.observation_space.sample(), env.action_space.sample() # an example state, an example action. Good for testing your environment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e4930-56f5-4797-8e99-83712d271a59",
   "metadata": {},
   "source": [
    "# Testing the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d9e08ab-a3e5-4ea5-a0a4-7692c2b675cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-46\n",
      "Episode:2 Score:-60\n",
      "Episode:3 Score:-12\n",
      "Episode:4 Score:-22\n",
      "Episode:5 Score:-14\n",
      "Episode:6 Score:-60\n",
      "Episode:7 Score:-38\n",
      "Episode:8 Score:-38\n",
      "Episode:9 Score:-30\n",
      "Episode:10 Score:-22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    \n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        #env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "\n",
    "\n",
    "    print('Episode:{} Score:{}'.format(episode,score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f21e1-a895-451e-a3ad-f8193b2db0dd",
   "metadata": {},
   "source": [
    "# Create the Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b92cd80-eda9-4212-83fa-d9260c760452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Deep Learning Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import gym\n",
    "import random\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0929c34-0a89-4ac2-8149-b22c0b427618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1,), 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n\n",
    "\n",
    "states, actions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03b9a3b8-494c-4a6d-8384-49aa0097fdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 24)                48        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 24)                600       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 75        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 723\n",
      "Trainable params: 723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(states, actions):\n",
    "    model = Sequential()\n",
    "    #model.add(Flatten(input_shape=(1,states))) flatten is needed if we have more than 1 dimensional actions\n",
    "    model.add(Dense(24, activation='relu', input_shape = states))\n",
    "    model.add(Dense(24, activation='relu')) # Two dense layers with 24 hyperparameters is customary. \n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model\n",
    "states = (1,)       # input shape for scalar state\n",
    "actions = 3         # number of possible actions\n",
    "model = build_model(states, actions)\n",
    "model.summary() #we can look at our model here)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9005e6f6-804c-44e9-b83c-18ad1fd83d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b8d285b-9ee2-48d8-83af-a07e49db869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(states, actions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9479a834-8562-47f8-be69-3e302e01f710",
   "metadata": {},
   "source": [
    "# Training Model with Keras-RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bb29f26-b210-4f18-a2ef-fca6a8e32668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_6_input to have 2 dimensions, but got array with shape (1, 1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m dqn \u001b[38;5;241m=\u001b[39m build_agent(model, actions)\n\u001b[0;32m      9\u001b[0m dqn\u001b[38;5;241m.\u001b[39mcompile(Adam(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 10\u001b[0m \u001b[43mdqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\rl\\core.py:168\u001b[0m, in \u001b[0;36mAgent.fit\u001b[1;34m(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)\u001b[0m\n\u001b[0;32m    165\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_step_begin(episode_step)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# This is were all of the work happens. We first perceive and compute the action\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# (forward step) and then use the reward to improve (backward step).\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mprocess_action(action)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\rl\\agents\\dqn.py:224\u001b[0m, in \u001b[0;36mDQNAgent.forward\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation):\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# Select an action.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mget_recent_state(observation)\n\u001b[1;32m--> 224\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_q_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m    226\u001b[0m         action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mselect_action(q_values\u001b[38;5;241m=\u001b[39mq_values)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\rl\\agents\\dqn.py:68\u001b[0m, in \u001b[0;36mAbstractDQNAgent.compute_q_values\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_q_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[1;32m---> 68\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_batch_q_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_values\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnb_actions,)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m q_values\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\rl\\agents\\dqn.py:63\u001b[0m, in \u001b[0;36mAbstractDQNAgent.compute_batch_q_values\u001b[1;34m(self, state_batch)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_batch_q_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, state_batch):\n\u001b[0;32m     62\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_state_batch(state_batch)\n\u001b[1;32m---> 63\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_values\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28mlen\u001b[39m(state_batch), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnb_actions)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m q_values\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training_v1.py:1304\u001b[0m, in \u001b[0;36mModel.predict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   1300\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`predict_on_batch` is not supported for models distributed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith tf.distribute.Strategy.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1302\u001b[0m     )\n\u001b[0;32m   1303\u001b[0m \u001b[38;5;66;03m# Validate and standardize user data.\u001b[39;00m\n\u001b[1;32m-> 1304\u001b[0m inputs, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_standardize_user_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_tensors_from_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m   1306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;66;03m# If `self._distribution_strategy` is True, then we are in a replica\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;66;03m# context at this point.\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_eagerly \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training_v1.py:2649\u001b[0m, in \u001b[0;36mModel._standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2641\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m run_eagerly\n\u001b[0;32m   2642\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_build_called\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2645\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(_is_symbolic_tensor(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m all_inputs)\n\u001b[0;32m   2646\u001b[0m ):\n\u001b[0;32m   2647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], [], \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2649\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_standardize_tensors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2651\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2652\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_eagerly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_eagerly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdict_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdict_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2658\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training_v1.py:2690\u001b[0m, in \u001b[0;36mModel._standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2687\u001b[0m \u001b[38;5;66;03m# Standardize the inputs.\u001b[39;00m\n\u001b[0;32m   2688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset, tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset)):\n\u001b[0;32m   2689\u001b[0m     \u001b[38;5;66;03m# TODO(fchollet): run static checks with dataset output shape(s).\u001b[39;00m\n\u001b[1;32m-> 2690\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_utils_v1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstandardize_input_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeed_input_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeed_input_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Don't enforce the batch size.\u001b[39;49;00m\n\u001b[0;32m   2695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2698\u001b[0m \u001b[38;5;66;03m# Get typespecs for the input data and sanitize it if necessary.\u001b[39;00m\n\u001b[0;32m   2699\u001b[0m \u001b[38;5;66;03m# TODO(momernick): This should be capable of doing full input validation\u001b[39;00m\n\u001b[0;32m   2700\u001b[0m \u001b[38;5;66;03m# at all times - validate that this is so and refactor the\u001b[39;00m\n\u001b[0;32m   2701\u001b[0m \u001b[38;5;66;03m# standardization code.\u001b[39;00m\n\u001b[0;32m   2702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset):\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training_utils_v1.py:714\u001b[0m, in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    712\u001b[0m shape \u001b[38;5;241m=\u001b[39m shapes[i]\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_shape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(shape):\n\u001b[1;32m--> 714\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    715\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when checking \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    716\u001b[0m         \u001b[38;5;241m+\u001b[39m exception_prefix\n\u001b[0;32m    717\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: expected \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;241m+\u001b[39m names[i]\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    720\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(shape))\n\u001b[0;32m    721\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dimensions, but got array \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith shape \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(data_shape)\n\u001b[0;32m    723\u001b[0m     )\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_batch_axis:\n\u001b[0;32m    725\u001b[0m     data_shape \u001b[38;5;241m=\u001b[39m data_shape[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_6_input to have 2 dimensions, but got array with shape (1, 1, 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_agent(model, actions): #building the 'agent'\n",
    "    policy = BoltzmannQPolicy() #Makes the agent try less optimal strategies for better results in the long term. \n",
    "    memory = SequentialMemory(limit=50000, window_length=1) #Stores past experiences\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
    "                  nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
    "    return dqn\n",
    "\n",
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a5424-af43-4147-a90a-b96bf6589432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
